{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6494723,"sourceType":"datasetVersion","datasetId":3753465}],"dockerImageVersionId":25114,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Step 1: Import required libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nimport seaborn as sns # for plot visualization\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.metrics import mean_squared_error","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 1 : Load the Data**","metadata":{}},{"cell_type":"code","source":"weather_df = pd.read_csv('/kaggle/input/bangladesh-historical-weather-dataset-2008-2023/Bangladesh Historical Weather Dataset 2008-2023.csv', parse_dates=['time'], index_col='time')\nweather_df.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 2: Feature Engineering**","metadata":{"_uuid":"80082f03824293a87be852453b96736a498f77c6"}},{"cell_type":"code","source":"weather_df = weather_df.loc[:,['precipitation_sum (mm)', 'sunrise (iso8601)',\n                               'sunset (iso8601)', 'temperature_2m_max (°C)', \n                               'temperature_2m_min (°C)', 'rain_sum (mm)', \n                               'temperature_2m_mean (°C)', 'snowfall_sum (cm)']]\n\nweather_df = weather_df.rename(index=str, columns={'precipitation_sum (mm)': 'precipitation',\n                                                   'sunrise (iso8601)': 'sunrise', \n                                                   'sunset (iso8601)': 'sunset', \n                                                   'temperature_2m_max (°C)':'temp_max',\n                                                   'temperature_2m_min (°C)':'temp_min',\n                                                   'temperature_2m_mean (°C)': 'temprature',\n                                                   'rain_sum (mm)':'rain',\n                                                  'snowfall_sum (cm)':'snowfall'})\n\nprint(f'dataset shape (rows, columns) - {weather_df.shape}')\nweather_df.head()","metadata":{"_uuid":"60c5df9aba4211f1e9ee9c608ee46903c6dbf230","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weather_df['temprature'] = (weather_df['temp_max'] + weather_df['temp_min']) / 2\n\n# weather_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check dtype of all columns, \nweather_df.dtypes, weather_df.index.dtype","metadata":{"_uuid":"65d8f367f96a2723a88b41898f5f5b8c20680f43","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It shows 'index' as object type which needs to be converted to datetime otherwise we won't be able to perform scaling during time series analysis.","metadata":{"_uuid":"07e3ca3a91e676dd699f9fc7565239caa6023765"}},{"cell_type":"code","source":"weather_df.index = pd.to_datetime(weather_df.index)\nweather_df.index","metadata":{"_uuid":"74ffcf7e44e4fb59395ff1607a4ad33d9cd6b49f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 3 : Data Preprocessing**","metadata":{"_uuid":"c0308ac54e25cabfc7cdb6cc34fc59a7f4b9448f"}},{"cell_type":"code","source":"def list_and_visualize_missing_data(dataset):\n    # Listing total null items and its percent with respect to all nulls\n    total = dataset.isnull().sum().sort_values(ascending=False)\n    percent = ((dataset.isnull().sum())/(dataset.isnull().count())).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    missing_data = missing_data[missing_data.Total >= 0]\n    #missing_data = missing_data[missing_data.Total > 0]\n\n    missing_data.plot.bar(subplots=True, figsize=(16,9))\n\nlist_and_visualize_missing_data(weather_df)","metadata":{"_uuid":"36451f00f83869fb7bea6af90c8f610426d50319","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# will fill with previous valid value\n#weather_df.ffill(inplace=True)\nweather_df=weather_df.dropna(axis=0)\nweather_df[weather_df.isnull()].count()","metadata":{"_uuid":"e7618905331f01a3de0819a46fde1915bba7e3aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_df.describe()","metadata":{"_uuid":"afa434aaad949a029f112cbe087b11ac8e45269b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weather_df = weather_df[weather_df.temprature < 50]\n# #weather_df = weather_df[weather_df.humidity <= 100]","metadata":{"_uuid":"01aceee96dd0dc0fe5c751d8df5169f94ff6659a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 4 : Exploratory Data Analysis & Visualizations**","metadata":{"_uuid":"4a69bf03d4cb53fec36a9c0b26cacbe16abc4e15"}},{"cell_type":"code","source":"weather_condition = (weather_df.temprature.value_counts()/(weather_df.temprature.value_counts().sum()))*100\nweather_condition.plot.bar(figsize=(16,9))\nplt.xlabel('Temperature')\nplt.ylabel('Percent')","metadata":{"_uuid":"d2d3c495742fd8197df89746b34935d65906abad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_df.plot(subplots=True, figsize=(20,12))","metadata":{"_uuid":"74215480529da6749a6e4a0c7376360a213f5093","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_df['2008':'2024'].resample('D').fillna(method='pad').plot(subplots=True, figsize=(20,12))","metadata":{"_uuid":"e6d83fa34afcbd439aa105dacd503efddc86222d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_df.drop(columns=['sunrise', 'sunset'], inplace=True)\nweather_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 5 : Split the dataset into training and testing sets**","metadata":{}},{"cell_type":"code","source":"train_df = weather_df['2008':'2020'].resample('M').mean().fillna(method='pad')\n\ntrain_df.drop(columns='precipitation', axis=1, inplace=True)\ntrain_df.drop(columns='temp_max', axis=1, inplace=True)\ntrain_df.drop(columns='temp_min', axis=1, inplace=True)\ntrain_df.drop(columns='rain', axis=1, inplace=True)\ntrain_df.drop(columns='snowfall', axis=1, inplace=True)\n\n\ntest_df = weather_df['2020':'2024'].resample('M').mean().fillna(method='pad')\n\ntest_df.drop(columns='precipitation', axis=1, inplace=True)\ntest_df.drop(columns='temp_max', axis=1, inplace=True)\ntest_df.drop(columns='temp_min', axis=1, inplace=True)\ntest_df.drop(columns='rain', axis=1, inplace=True)\ntest_df.drop(columns='snowfall', axis=1, inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check rolling mean and rolling standard deviation\ndef plot_rolling_mean_std(ts):\n    rolling_mean = ts.rolling(12).mean()\n    rolling_std = ts.rolling(12).std()\n    plt.figure(figsize=(22,10))\n\n    plt.plot(ts, label='Actual Mean')\n    plt.plot(rolling_mean, label='Rolling Mean')\n    plt.plot(rolling_std, label = 'Rolling Std')\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Mean Temperature\")\n    plt.title('Rolling Mean & Rolling Standard Deviation')\n    plt.legend()\n    plt.show()","metadata":{"_uuid":"6b90db0d9107464d32387ae761548b70478cd8e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmented Dickey–Fuller test\ndef perform_dickey_fuller_test(ts):\n    result = adfuller(ts, autolag='AIC')\n    print('Test statistic: ' , result[0])\n    print('Critical Values:' ,result[4])","metadata":{"_uuid":"aadd34d0635379882191006195cc4dc1eddc76f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check stationary: mean, variance(std)and adfuller test\nplot_rolling_mean_std(train_df.temprature)\nperform_dickey_fuller_test(train_df.temprature)","metadata":{"_uuid":"c774e93db59c5598c6321f456e7c96daa6265b7c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original Series\nplt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(train_df.values); \naxes[0, 0].set_title('Original Series')\nplot_acf(train_df.values, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(train_df.temprature.diff().values); \naxes[1, 0].set_title('1st Order Differencing')\nplot_acf(train_df.diff().dropna().values,ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(train_df.temprature.diff().diff().values); \naxes[2, 0].set_title('2nd Order Differencing')\nplot_acf(train_df.diff().diff().dropna().values,ax=axes[2, 1])\n\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PACF plot of 1st differenced series\nplt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n\nfig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(train_df.diff().values); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,5))\nplot_pacf(train_df.diff().dropna().values, ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(train_df.diff().values); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,1.2))\nplot_acf(train_df.diff().dropna().values, ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acf_lag = acf(train_df.diff().dropna().values, nlags=20)\npacf_lag = pacf(train_df.diff().dropna().values, nlags=20, method='ols')\n\nplt.figure(figsize=(22,10))\n\nplt.subplot(121)\nplt.plot(acf_lag)\nplt.axhline(y=0,linestyle='--',color='silver')\nplt.axhline(y=-1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.axhline(y=1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.title(\"Autocorrelation Function\")\n\nplt.subplot(122)\nplt.plot(pacf_lag)\nplt.axhline(y=0,linestyle='--',color='silver')\nplt.axhline(y=-1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.axhline(y=1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.title(\"Partial Autocorrelation Function\")\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 6 : Model Building and Training**","metadata":{}},{"cell_type":"code","source":"#default order=(2,0,2), thesis paper order=(2,1,1)\nmodel = ARIMA(train_df.values, order=(2,0,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 7 : Predictions and Model evaluation**","metadata":{}},{"cell_type":"code","source":"# Plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nfig, ax = plt.subplots(1,2)\nresiduals.plot(title=\"Residuals\", ax=ax[0])\nresiduals.plot(kind='kde', title='Density', ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actual vs Fitted\nmodel_fit.plot_predict(dynamic=False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 8 : Weather Forecast**","metadata":{}},{"cell_type":"code","source":"# # Forecast\nfc, se, conf = model_fit.forecast(48, alpha=0.05)\n\nprint(fc)\n# Make as pandas series\nfc_series = pd.Series(fc, index=test_df.index)\nlower_series = pd.Series(conf[:, 0], index=test_df.index)\nupper_series = pd.Series(conf[:, 1], index=test_df.index)\n\n# # Plot\nplt.figure(figsize=(16,5), dpi=100)\nplt.plot(train_df, label='training')\nplt.plot(test_df, label='actual')\nplt.plot(fc_series, label='forecast')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.15)\nplt.title('Forecast vs Actuals')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()\n# test_df.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot Testing and Forecasted data\nplt.plot(test_df, label='Actual')\nplt.plot(fc_series, label='Forecast', color='red')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the forecast values with dates\nforecast_result = pd.DataFrame({'Date': test_df.index, 'Actual': test_df.values.flatten(), 'Forecast': fc_series.values})\nprint(forecast_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step 9 : Calculate the evaluation metrices**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nimport numpy as np\n\n# Assuming you have your true values and predicted values\ntrue_values = test_df  # Replace with your true values\npredicted_values = fc_series  # Replace with your predicted values\n\n# Calculate MSE\nmse = mean_squared_error(test_df, fc_series)\nprint('Test Mean Squared Error (MSE): ',mse)\n\n# Calculate MAE\nmae = mean_absolute_error(true_values, predicted_values)\nprint('Mean Absolute Error (MAE): ', mae)\n\n# Calculate RMSE\nrmse = np.sqrt(mean_squared_error(true_values, predicted_values))\nprint('Root Mean Squared Error (RMSE): ', rmse)\n\n# Calculate MAPE\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\nmape = mean_absolute_percentage_error(true_values, predicted_values)\nprint('Mean Absolute Percentage Error (MAPE): ', mape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fc_series.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'test_df' and 'fc_series' have the same index\nresult_df = pd.DataFrame({\n    'Date': test_df.index,\n    'Actual': test_df.values.flatten(),  # Flatten to 1D array\n    'Predicted': fc_series.values.flatten(),  # Flatten to 1D array\n    'Lower Bound': lower_series.values.flatten(),  # Flatten to 1D array\n    'Upper Bound': upper_series.values.flatten()  # Flatten to 1D array\n})\n\n# Display the DataFrame\nprint(result_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Rainfall**","metadata":{}},{"cell_type":"code","source":"weather_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# will fill with previous valid value\nweather_df.ffill(inplace=True)\nweather_df[weather_df.isnull()].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = weather_df['2008':'2020'].resample('M').mean().fillna(method='pad')\n\ntrain_df.drop(columns='precipitation', axis=1, inplace=True)\ntrain_df.drop(columns='temp_max', axis=1, inplace=True)\ntrain_df.drop(columns='temp_min', axis=1, inplace=True)\ntrain_df.drop(columns='temprature', axis=1, inplace=True)\ntrain_df.drop(columns='snowfall', axis=1, inplace=True)\n\ntest_df = weather_df['2020':'2024'].resample('M').mean().fillna(method='pad')\n\ntest_df.drop(columns='precipitation', axis=1, inplace=True)\ntest_df.drop(columns='temp_max', axis=1, inplace=True)\ntest_df.drop(columns='temp_min', axis=1, inplace=True)\ntest_df.drop(columns='temprature', axis=1, inplace=True)\ntest_df.drop(columns='snowfall', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check rolling mean and rolling standard deviation\ndef plot_rolling_mean_std(ts):\n    rolling_mean = ts.rolling(12).mean()\n    rolling_std = ts.rolling(12).std()\n    plt.figure(figsize=(22,10))\n\n    plt.plot(ts, label='Actual Mean')\n    plt.plot(rolling_mean, label='Rolling Mean')\n    plt.plot(rolling_std, label = 'Rolling Std')\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Mean Temperature\")\n    plt.title('Rolling Mean & Rolling Standard Deviation')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmented Dickey–Fuller test\ndef perform_dickey_fuller_test(ts):\n    result = adfuller(ts, autolag='AIC')\n    print('Test statistic: ' , result[0])\n    print('Critical Values:' ,result[4])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check stationary: mean, variance(std)and adfuller test\nplot_rolling_mean_std(train_df.rain)\nperform_dickey_fuller_test(train_df.rain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original Series\nplt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(train_df.values); \naxes[0, 0].set_title('Original Series')\nplot_acf(train_df.values, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(train_df.rain.diff().values); \naxes[1, 0].set_title('1st Order Differencing')\nplot_acf(train_df.diff().dropna().values,ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(train_df.rain.diff().diff().values); \naxes[2, 0].set_title('2nd Order Differencing')\nplot_acf(train_df.diff().diff().dropna().values,ax=axes[2, 1])\n\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PACF plot of 1st differenced series\nplt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n\nfig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(train_df.diff().values); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,5))\nplot_pacf(train_df.diff().dropna().values, ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(train_df.diff().values); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,1.2))\nplot_acf(train_df.diff().dropna().values, ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acf_lag = acf(train_df.diff().dropna().values, nlags=20)\npacf_lag = pacf(train_df.diff().dropna().values, nlags=20, method='ols')\n\nplt.figure(figsize=(22,10))\n\nplt.subplot(121)\nplt.plot(acf_lag)\nplt.axhline(y=0,linestyle='--',color='silver')\nplt.axhline(y=-1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.axhline(y=1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.title(\"Autocorrelation Function\")\n\nplt.subplot(122)\nplt.plot(pacf_lag)\nplt.axhline(y=0,linestyle='--',color='silver')\nplt.axhline(y=-1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.axhline(y=1.96/np.sqrt(len(train_df.diff().values)),linestyle='--',color='silver')\nplt.title(\"Partial Autocorrelation Function\")\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#default order=(2,0,2), thesis paper order=(2,1,1)\nmodel = ARIMA(train_df.values, order=(2,0,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nfig, ax = plt.subplots(1,2)\nresiduals.plot(title=\"Residuals\", ax=ax[0])\nresiduals.plot(kind='kde', title='Density', ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actual vs Fitted\nmodel_fit.plot_predict(dynamic=False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Forecast\nfc, se, conf = model_fit.forecast(24, alpha=0.05)\n\n# print(fc)\n# Make as pandas series\nfc_series = pd.Series(fc, index=test_df.index)\nlower_series = pd.Series(conf[:, 0], index=test_df.index)\nupper_series = pd.Series(conf[:, 1], index=test_df.index)\n\n# # Plot\nplt.figure(figsize=(16,5), dpi=100)\nplt.plot(train_df, label='training')\nplt.plot(test_df, label='actual')\nplt.plot(fc_series, label='forecast')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.15)\nplt.title('Forecast vs Actuals')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()\n# test_df.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot Testing and Forecasted data\nplt.plot(test_df, label='Actual')\nplt.plot(fc_series, label='Forecast', color='red')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have your true values and predicted values\ntrue_values = test_df  # Replace with your true values\npredicted_values = fc_series  # Replace with your predicted values\n\n# Calculate MSE\nmse = mean_squared_error(test_df, fc_series)\nprint('Test Mean Squared Error (MSE): ',mse)\n\n# Calculate MAE\nmae = mean_absolute_error(true_values, predicted_values)\nprint('Mean Absolute Error (MAE): ', mae)\n\n# Calculate RMSE\nrmse = np.sqrt(mean_squared_error(true_values, predicted_values))\nprint('Root Mean Squared Error (RMSE): ', rmse)\n\n# Calculate MAPE\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\nmape = mean_absolute_percentage_error(true_values, predicted_values)\nprint('Mean Absolute Percentage Error (MAPE): ', mape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'test_df' and 'fc_series' have the same index\nresult_df = pd.DataFrame({\n    'Date': test_df.index,\n    'Actual': test_df.values.flatten(),  # Flatten to 1D array\n    'Predicted': fc_series.values.flatten(),  # Flatten to 1D array\n    'Lower Bound': lower_series.values.flatten(),  # Flatten to 1D array\n    'Upper Bound': upper_series.values.flatten()  # Flatten to 1D array\n})\n\n# Display the DataFrame\nprint(result_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}